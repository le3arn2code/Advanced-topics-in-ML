# Interview Q&A

**1Ô∏è‚É£ What is DistilBERT?**
A distilled version of BERT ‚Äî smaller, faster, but with nearly the same performance.

**2Ô∏è‚É£ Why use IMDB dataset?**
It's a classic benchmark for binary sentiment classification.

**3Ô∏è‚É£ What library is used for training?**
HuggingFace Transformers + Datasets + PyTorch.

**4Ô∏è‚É£ What does tokenizer do?**
Converts text into numerical tokens understandable by the model.

**5Ô∏è‚É£ Why save model with `save_pretrained()`?**
It stores model architecture + weights + tokenizer files for easy reload.

**6Ô∏è‚É£ What is softmax used for?**
To convert logits into probability scores.

**7Ô∏è‚É£ How do you prevent model duplication?**
Using a flag file `save_complete.flag` in the results folder.

**8Ô∏è‚É£ What is the /predict endpoint for?**
To take user input and return sentiment prediction via Flask API.

**9Ô∏è‚É£ Why use Flask here?**
It‚Äôs lightweight and perfect for serving ML inference APIs.

**üîü How to deploy this API to production?**
Containerize with Docker + Gunicorn, deploy on cloud (AWS/Azure/GCP).
