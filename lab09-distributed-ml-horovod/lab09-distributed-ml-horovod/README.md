# Lab 09 â€“ Distributed Machine Learning with Horovod (CPU-only)

## ğŸ¯ Objective
Implement distributed training on TensorFlow using **Horovod (CPU-only)**.  
This lab demonstrates multi-process training using MPI on a t3.medium instance.

## âš™ï¸ Environment
- **OS:** Ubuntu 24.04 LTS
- **Instance Type:** t3.medium (2 vCPU, 4GB RAM)
- **Python:** 3.12.x
- **TensorFlow:** 2.16.1 (CPU-only)
- **Horovod:** 0.28.1 (built with Gloo backend)

---

## ğŸ§© Steps Overview
1. Install prerequisites and dependencies.
2. Install TensorFlow CPU.
3. Build Horovod with TensorFlow ops (CPU backend).
4. Verify MPI communication.
5. Run distributed training with Horovod.

---

## ğŸ§± Setup Commands
See `commands.sh` for the full reproducible command list.

---

## ğŸ§ª Verification
```bash
mpirun --oversubscribe -np 2 python3 code/test_mpi_rank.py
```
Expected output:
```
Rank 0 OK
Rank 1 OK
```

Run training:
```bash
mpirun --oversubscribe -np 2 python3 code/train_horovod_tf.py
```

---

## ğŸ§  Deliverables
- `README.md` â€“ overview & objectives  
- `commands.sh` â€“ setup & run steps  
- `troubleshooting.md` â€“ errors & fixes  
- `interview_qna.md` â€“ 10 real Q&A  
- `layman_explanation.md` â€“ simplified summary  
- `code/` â€“ Python scripts  
- `screenshots/` â€“ training output images  

---

âœ… **This lab completes the Horovod CPU Distributed ML pipeline as per the course document.**
