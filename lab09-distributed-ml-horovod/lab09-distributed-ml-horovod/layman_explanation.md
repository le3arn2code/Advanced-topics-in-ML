# ðŸ§  Layman Explanation

This lab shows how multiple CPU processes can train a neural network together.

Horovod makes TensorFlow run the same code on several processes that **communicate** through MPI.
Each process trains a copy of the model, shares gradients, and updates weights together.
On small CPU machines (like t3.medium), this demonstrates distributed learning **without GPUs**.
